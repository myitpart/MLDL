{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyND9TMb/saN/mhQ4NXRzMQz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# install & setup"],"metadata":{"id":"y4WcKat4tlOU"}},{"cell_type":"code","source":["!pip install opencv-python ultralytics numpy"],"metadata":{"id":"jvT5x_a-nEzf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!ls"],"metadata":{"id":"DWnzo8z3rFvG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"ZzId7g3186vL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIha_7Rth3ll"},"outputs":[],"source":["from ultralytics import YOLO\n","import random\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","\n","model = YOLO(\"yolo11x-seg.pt\")"]},{"cell_type":"code","source":["imgfile = '/content/drive/MyDrive/Colab Notebooks/datasets/DL/sample_city.jpg'\n","# imgfile = '/content/drive/MyDrive/Colab Notebooks/datasets/DL/cat615m.jpg'\n","# imgfile = '/content/drive/MyDrive/Colab Notebooks/datasets/DL/bird1.jpg'\n","# img = cv2.imread(imgfile)\n","# img\n","\n","try:\n","  img = cv2.imread(imgfile)\n","  if img is not None:\n","    cv2_imshow(img)\n","  else:\n","    print(f\"Error: Could not read image {imgfile} \")\n","except Exception as e:\n","  print(f\"An error occurred: {e}\")"],"metadata":{"id":"eEJT95YDHntH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# imgfile = '/content/drive/MyDrive/Colab Notebooks/datasets/DL/sample_city.jpg'\n","# imgfile = '/content/drive/MyDrive/Colab Notebooks/datasets/DL/cat615m.jpg'\n","# img = cv2.imread(imgfile)\n","\n","# all classes\n","yolo_classes = list(model.names.values())\n","classes_ids = [yolo_classes.index(clas) for clas in yolo_classes]\n","\n","conf = 0.2\n","\n","results = model.predict(img, conf=conf)\n","colors = [random.choices(range(256), k=3) for _ in classes_ids]\n","\n","for result in results:\n","    for mask, box in zip(result.masks.xy, result.boxes):\n","        points = np.int32([mask])\n","        color_number = classes_ids.index(int(box.cls[0]))\n","        cv2.fillPoly(img, points, colors[color_number])\n","\n","# cv2.imshow(\"Image\", img)\n","# cv2.waitKey(0)\n","# cv2.imwrite(\"YourSavePath\", img)"],"metadata":{"id":"cpP1Bqy26YFp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img"],"metadata":{"id":"dKBV7V6Q-poV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mask and crop"],"metadata":{"id":"ONL_o-afE-aA"}},{"cell_type":"code","source":["# create mask for cropping\n","\n","import numpy as np\n","\n","def create_mask(results, img_shape):\n","  \"\"\"Creates a mask for cropping based on YOLO segmentation results.\n","\n","  Args:\n","      results: YOLO prediction results.\n","      img_shape: Shape of the original image (height, width).\n","\n","  Returns:\n","      A binary mask (NumPy array) where 1 represents the area to keep.\n","  \"\"\"\n","\n","  mask = np.zeros(img_shape[:2], dtype=np.uint8)\n","  for result in results:\n","      for box, mask_data in zip(result.boxes, result.masks.xy):\n","          # keep the areas with detected objects\n","          points = np.int32([mask_data])\n","          cv2.fillPoly(mask, points, 255)  # Fill the polygon with white (255)\n","  return mask\n","\n","\n","#  'results' from your YOLO prediction)\n","img = cv2.imread(imgfile)\n","img_shape = img.shape  # Get shape of the image\n","combined_mask = create_mask(results, img_shape)\n","\n","# # To crop the image based on the mask:\n","cropped_img = cv2.bitwise_and(img, img, mask=combined_mask)\n","\n","cv2_imshow(cropped_img)\n"],"metadata":{"id":"AJ9Fq-EtBP45"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  white background\n","\n","# Create a white background image\n","white_background = np.full(img.shape, 255, dtype=np.uint8)\n","\n","# Use the combined mask to extract the object from the original image\n","extracted_object = cv2.bitwise_and(img, img, mask=combined_mask)\n","\n","# Combine the extracted object with the white background\n","final_image = np.where(combined_mask[..., None] == 0, white_background, extracted_object)\n","\n","\n","cv2_imshow(final_image)"],"metadata":{"id":"hiIlN7SMFmyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_mask"],"metadata":{"id":"HqLI6C2CBWqS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for r in results:\n","    print(r.boxes)\n","# yolo_classes"],"metadata":{"id":"E0meAexQ7Tkl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KGtmMecxCpVQ"},"execution_count":null,"outputs":[]}]}